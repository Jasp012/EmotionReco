{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model on RAF DB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "from generator_RAF import RAFDataset\n",
    "import os\n",
    "import torchvision as tv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "size=(160,120)\n",
    "data_transforms = tv.transforms.Compose([\n",
    "        tv.transforms.Resize(size),\n",
    "        tv.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "train_dataset = RAFDataset(\n",
    "        d_set='train',\n",
    "        params=[False],\n",
    "        transform=data_transforms\n",
    "    )\n",
    "print(len(train_dataset))\n",
    "img,target=next(iter(train_dataset))\n",
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_raf_data import *\n",
    "size=(160,120)\n",
    "batch_size=16\n",
    "trainloader,validloader,testloader=load_data(batch_size=batch_size,size=size,data_augmentation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_model import load_model\n",
    "\n",
    "model,optimizer,criterion,device=load_model(baseline='inception_resnetV1',freeze_layer='block8',\n",
    "          GPU=0,lr=1e-5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize global variables\n",
    "filename=os.path.join('./Checkpoints/','Inception_resnetV1_RafDB_block8'+str(size)\\\n",
    "                       +'_'+str(batch_size)+'.pth.tar')\n",
    "\n",
    "csv_path=os.path.join('./Logs/','Inception_resnetV1_RafDB_block8'+str(size)\\\n",
    "                       +'_'+str(batch_size)+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model_raf import train_model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()\n",
    "\n",
    "train_model(tb,model,optimizer,criterion,\n",
    "          trainloader,validloader, filename, csv_path,\n",
    "          device=device)\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from global_main import main\n",
    "import os\n",
    "parameters = dict(\n",
    "    lr = [1e-5, 1e-4],\n",
    "    batch_size = [16],\n",
    "    layer= ['block8'],\n",
    "    dropout_prob=[0.6,0.3,0.0],\n",
    "    data_augmentation = [False]\n",
    ")\n",
    "model_name= 'inception_resnetV1'\n",
    "param_values = [v for v in parameters.values()]\n",
    "print(param_values)\n",
    "print(f'num combinations={len(list(product(*param_values)))}')\n",
    "for lr,batch_size, layer, dropout_prob, data_augmentation in product(*param_values):\n",
    "    filename = '_'.join((model_name, str(batch_size), str(layer), str(lr), str(dropout_prob)))\n",
    "    print(filename)\n",
    "    params={'model_name':model_name,\n",
    "            'filename': filename,\n",
    "            'lr': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'layer': layer, \n",
    "            'dropout_prob': dropout_prob,\n",
    "            'data_augmentation': data_augmentation}\n",
    "    print(model_name, lr, batch_size, layer, dropout_prob, data_augmentation)\n",
    "    \n",
    "    main(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
